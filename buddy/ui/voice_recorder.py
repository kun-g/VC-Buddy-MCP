import os
import tempfile
import threading
import wave
from typing import Optional, Callable
import pyaudio
import openai
from PySide6.QtCore import QObject, Signal, QThread
from PySide6.QtWidgets import QPushButton, QMessageBox


class VoiceRecorder(QObject):
    """è¯­éŸ³å½•åˆ¶å™¨"""
    
    # ä¿¡å·å®šä¹‰
    recording_started = Signal()
    recording_stopped = Signal()
    transcription_ready = Signal(str)  # è½¬å†™ç»“æœ
    error_occurred = Signal(str)  # é”™è¯¯ä¿¡æ¯
    audio_saved = Signal(str)  # éŸ³é¢‘æ–‡ä»¶ä¿å­˜å®Œæˆï¼Œä¼ é€’æ–‡ä»¶è·¯å¾„
    
    def __init__(self):
        super().__init__()
        self.is_recording = False
        self.audio_data = []
        self.stream = None
        self.audio = None
        self.last_audio_file = None  # ä¿å­˜æœ€åå½•åˆ¶çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
        # éŸ³é¢‘å‚æ•°
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000
        
        # OpenAI å®¢æˆ·ç«¯
        self.openai_client = None
        self._init_openai_client()
    
    def _init_openai_client(self):
        """åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯"""
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key:
            self.openai_client = openai.OpenAI(api_key=api_key)
        else:
            print("Warning: OPENAI_API_KEY not found in environment variables")
    
    def start_recording(self):
        """å¼€å§‹å½•éŸ³"""
        if self.is_recording:
            return
        
        try:
            self.audio = pyaudio.PyAudio()
            self.stream = self.audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk
            )
            
            self.is_recording = True
            self.audio_data = []
            
            # åœ¨æ–°çº¿ç¨‹ä¸­å½•éŸ³
            self.recording_thread = threading.Thread(target=self._record_audio)
            self.recording_thread.start()
            
            self.recording_started.emit()
            
        except Exception as e:
            self.error_occurred.emit(f"å½•éŸ³å¯åŠ¨å¤±è´¥: {str(e)}")
    
    def stop_recording(self):
        """åœæ­¢å½•éŸ³"""
        if not self.is_recording:
            return
        
        self.is_recording = False
        
        # ç­‰å¾…å½•éŸ³çº¿ç¨‹ç»“æŸ
        if hasattr(self, 'recording_thread'):
            self.recording_thread.join()
        
        # æ¸…ç†èµ„æº
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        if self.audio:
            self.audio.terminate()
        
        self.recording_stopped.emit()
        
        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        if self.audio_data:
            self._save_audio_file()
            self._start_transcription()
    
    def _record_audio(self):
        """å½•éŸ³çº¿ç¨‹å‡½æ•°"""
        while self.is_recording:
            try:
                data = self.stream.read(self.chunk, exception_on_overflow=False)
                self.audio_data.append(data)
            except Exception as e:
                self.error_occurred.emit(f"å½•éŸ³è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                break
    
    def _save_audio_file(self):
        """ä¿å­˜éŸ³é¢‘æ–‡ä»¶"""
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜å½•éŸ³
            temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
            self.last_audio_file = temp_file.name
            temp_file.close()
            
            # å†™å…¥ WAV æ–‡ä»¶
            with wave.open(self.last_audio_file, 'wb') as wf:
                wf.setnchannels(self.channels)
                wf.setsampwidth(self.audio.get_sample_size(self.format))
                wf.setframerate(self.rate)
                wf.writeframes(b''.join(self.audio_data))
            
            self.audio_saved.emit(self.last_audio_file)
            
        except Exception as e:
            self.error_occurred.emit(f"ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def play_last_recording(self):
        """æ’­æ”¾æœ€åå½•åˆ¶çš„éŸ³é¢‘"""
        if not self.last_audio_file or not os.path.exists(self.last_audio_file):
            self.error_occurred.emit("æ²¡æœ‰æ‰¾åˆ°å½•éŸ³æ–‡ä»¶")
            return
        
        # åœ¨æ–°çº¿ç¨‹ä¸­æ’­æ”¾éŸ³é¢‘
        play_thread = threading.Thread(target=self._play_audio_file, args=(self.last_audio_file,))
        play_thread.start()
    
    def _play_audio_file(self, file_path: str):
        """æ’­æ”¾éŸ³é¢‘æ–‡ä»¶"""
        try:
            # è¯»å–éŸ³é¢‘æ–‡ä»¶
            with wave.open(file_path, 'rb') as wf:
                # åˆ›å»ºéŸ³é¢‘è¾“å‡ºæµ
                audio_output = pyaudio.PyAudio()
                stream = audio_output.open(
                    format=audio_output.get_format_from_width(wf.getsampwidth()),
                    channels=wf.getnchannels(),
                    rate=wf.getframerate(),
                    output=True
                )
                
                # æ’­æ”¾éŸ³é¢‘æ•°æ®
                chunk_size = 1024
                data = wf.readframes(chunk_size)
                while data:
                    stream.write(data)
                    data = wf.readframes(chunk_size)
                
                # æ¸…ç†èµ„æº
                stream.stop_stream()
                stream.close()
                audio_output.terminate()
                
        except Exception as e:
            self.error_occurred.emit(f"æ’­æ”¾éŸ³é¢‘å¤±è´¥: {str(e)}")
    
    def _start_transcription(self):
        """å¼€å§‹è½¬å†™éŸ³é¢‘"""
        if not self.openai_client:
            self.error_occurred.emit("OpenAI API æœªé…ç½®ï¼Œæ— æ³•è¿›è¡Œè¯­éŸ³è½¬å†™")
            return
        
        # åœ¨æ–°çº¿ç¨‹ä¸­è¿›è¡Œè½¬å†™
        transcription_thread = threading.Thread(target=self._transcribe_audio)
        transcription_thread.start()
    
    def _transcribe_audio(self):
        """è½¬å†™éŸ³é¢‘"""
        try:
            if not self.last_audio_file or not os.path.exists(self.last_audio_file):
                self.error_occurred.emit("éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œè½¬å†™")
                return
            
            # è°ƒç”¨ OpenAI Whisper API
            with open(self.last_audio_file, 'rb') as audio_file:
                transcript = self.openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="zh"  # æŒ‡å®šä¸­æ–‡
                )
            
            # å‘é€è½¬å†™ç»“æœ
            self.transcription_ready.emit(transcript.text)
            
        except Exception as e:
            self.error_occurred.emit(f"è¯­éŸ³è½¬å†™å¤±è´¥: {str(e)}")
    
    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if self.last_audio_file and os.path.exists(self.last_audio_file):
            try:
                os.unlink(self.last_audio_file)
            except Exception:
                pass  # å¿½ç•¥åˆ é™¤æ–‡ä»¶çš„é”™è¯¯


class VoiceButton(QPushButton):
    """è¯­éŸ³å½•åˆ¶æŒ‰é’®"""
    
    def __init__(self, parent=None):
        super().__init__("ğŸ¤", parent)
        self.setToolTip("ç‚¹å‡»å¼€å§‹å½•éŸ³ï¼Œå†æ¬¡ç‚¹å‡»åœæ­¢å½•éŸ³")
        self.setFixedSize(40, 40)
        
        # åˆ›å»ºå½•éŸ³å™¨
        self.recorder = VoiceRecorder()
        
        # è¿æ¥ä¿¡å·
        self.recorder.recording_started.connect(self._on_recording_started)
        self.recorder.recording_stopped.connect(self._on_recording_stopped)
        self.recorder.error_occurred.connect(self._on_error)
        
        # è¿æ¥æŒ‰é’®ç‚¹å‡»äº‹ä»¶
        self.clicked.connect(self._toggle_recording)
        
        # æ ·å¼
        self.setStyleSheet("""
            QPushButton {
                background-color: #f0f0f0;
                border: 2px solid #ccc;
                border-radius: 20px;
                font-size: 16px;
            }
            QPushButton:hover {
                background-color: #e0e0e0;
                border-color: #999;
            }
            QPushButton:pressed {
                background-color: #d0d0d0;
            }
            QPushButton[recording="true"] {
                background-color: #ff4444;
                border-color: #cc0000;
                color: white;
            }
        """)
    
    def _toggle_recording(self):
        """åˆ‡æ¢å½•éŸ³çŠ¶æ€"""
        if self.recorder.is_recording:
            self.recorder.stop_recording()
        else:
            self.recorder.start_recording()
    
    def _on_recording_started(self):
        """å½•éŸ³å¼€å§‹æ—¶çš„å¤„ç†"""
        self.setText("â¹ï¸")
        self.setToolTip("ç‚¹å‡»åœæ­¢å½•éŸ³")
        self.setProperty("recording", "true")
        self.style().unpolish(self)
        self.style().polish(self)
    
    def _on_recording_stopped(self):
        """å½•éŸ³åœæ­¢æ—¶çš„å¤„ç†"""
        self.setText("ğŸ¤")
        self.setToolTip("ç‚¹å‡»å¼€å§‹å½•éŸ³ï¼Œå†æ¬¡ç‚¹å‡»åœæ­¢å½•éŸ³")
        self.setProperty("recording", "false")
        self.style().unpolish(self)
        self.style().polish(self)
    
    def _on_error(self, error_message: str):
        """é”™è¯¯å¤„ç†"""
        QMessageBox.warning(self, "è¯­éŸ³å½•åˆ¶é”™è¯¯", error_message)
        self._on_recording_stopped()  # é‡ç½®æŒ‰é’®çŠ¶æ€
    
    def connect_transcription_ready(self, callback: Callable[[str], None]):
        """è¿æ¥è½¬å†™å®Œæˆçš„å›è°ƒå‡½æ•°"""
        self.recorder.transcription_ready.connect(callback)


class PlayButton(QPushButton):
    """æ’­æ”¾å½•éŸ³æŒ‰é’®"""
    
    def __init__(self, voice_recorder: VoiceRecorder, parent=None):
        super().__init__("ğŸ”Š", parent)
        self.setToolTip("æ’­æ”¾æœ€åå½•åˆ¶çš„éŸ³é¢‘")
        self.setFixedSize(40, 40)
        self.setEnabled(False)  # åˆå§‹çŠ¶æ€ç¦ç”¨
        
        self.voice_recorder = voice_recorder
        
        # è¿æ¥ä¿¡å·
        self.voice_recorder.audio_saved.connect(self._on_audio_saved)
        self.voice_recorder.error_occurred.connect(self._on_error)
        
        # è¿æ¥æŒ‰é’®ç‚¹å‡»äº‹ä»¶
        self.clicked.connect(self._play_audio)
        
        # æ ·å¼
        self.setStyleSheet("""
            QPushButton {
                background-color: #f0f0f0;
                border: 2px solid #ccc;
                border-radius: 20px;
                font-size: 16px;
            }
            QPushButton:hover:enabled {
                background-color: #e0e0e0;
                border-color: #999;
            }
            QPushButton:pressed:enabled {
                background-color: #d0d0d0;
            }
            QPushButton:disabled {
                background-color: #f8f8f8;
                border-color: #ddd;
                color: #ccc;
            }
        """)
    
    def _play_audio(self):
        """æ’­æ”¾éŸ³é¢‘"""
        self.voice_recorder.play_last_recording()
    
    def _on_audio_saved(self, file_path: str):
        """éŸ³é¢‘ä¿å­˜å®Œæˆï¼Œå¯ç”¨æ’­æ”¾æŒ‰é’®"""
        self.setEnabled(True)
        self.setToolTip("æ’­æ”¾æœ€åå½•åˆ¶çš„éŸ³é¢‘")
    
    def _on_error(self, error_message: str):
        """é”™è¯¯å¤„ç†"""
        if "æ’­æ”¾éŸ³é¢‘å¤±è´¥" in error_message or "æ²¡æœ‰æ‰¾åˆ°å½•éŸ³æ–‡ä»¶" in error_message:
            QMessageBox.warning(self, "æ’­æ”¾é”™è¯¯", error_message) 